{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d1ea4cab",
      "metadata": {
        "id": "d1ea4cab"
      },
      "source": [
        "fyzCgTU9Iq9Fq1kj"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q google-generativeai langchain langchain-community langchain-google-genai\n",
        "!pip install pymongo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewL4gfk5ZRpP",
        "outputId": "be700223-c2e4-4ff7-a629-ee9a866a8200"
      },
      "id": "ewL4gfk5ZRpP",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.12/dist-packages (4.14.1)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from pymongo) (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "ecda52a6",
      "metadata": {
        "id": "ecda52a6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from pymongo import MongoClient\n",
        "from pymongo.operations import SearchIndexModel\n",
        "from transformers import pipeline\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "mongodb_connection_string = userdata.get(\"GoogleAPIKey\")\n",
        "gemini_api_key = userdata.get(\"GoogleAPIKey\")\n"
      ],
      "metadata": {
        "id": "LrBj8iSMZ_RW"
      },
      "id": "LrBj8iSMZ_RW",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4508b636",
      "metadata": {
        "id": "4508b636"
      },
      "source": [
        "# Using HuggingFace Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "73eb8c82",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73eb8c82",
        "outputId": "ff0ef7eb-d5d4-40f2-c65d-de16a7a09cb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers_modules.nomic-ai.nomic-bert-2048.7710840340a098cfb869c4f65e87cf2b1b70caca.modeling_hf_nomic_bert:<All keys matched successfully>\n"
          ]
        }
      ],
      "source": [
        "model = SentenceTransformer(\"nomic-ai/nomic-embed-text-v1.5\" , trust_remote_code = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8283d9fe",
      "metadata": {
        "id": "8283d9fe"
      },
      "source": [
        "## Setting up the database\n",
        "To query a database, you first need to set one up.\n",
        "\n",
        "1. **Load the California Housing Dataset:** Load the dataset from sklearn.datasets and extract it into a DataFrame.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "california_housing_bunch = fetch_california_housing(as_frame=True)\n",
        "california_housing_df = california_housing_bunch.frame\n",
        "records = california_housing_df.to_dict(orient=\"records\")"
      ],
      "metadata": {
        "id": "jZiNgMrCa-mv"
      },
      "id": "jZiNgMrCa-mv",
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a008505a",
      "metadata": {
        "id": "a008505a"
      },
      "source": [
        "2. **Connect to the mongo database and insert records:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = MongoClient(mongodb_connection_string)\n",
        "db = client[\"sample_db\"]\n",
        "collection = db[\"housing_data\"]\n",
        "collection.insert_many(records)\n",
        "print(\"DataFrame successfully inserted into MongoDB.\")"
      ],
      "metadata": {
        "id": "mEvHWK8Uczy3"
      },
      "id": "mEvHWK8Uczy3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "bf2bbff3",
      "metadata": {
        "id": "bf2bbff3"
      },
      "source": [
        "# Creating RAG Pipeline with Langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0904e5b8",
      "metadata": {
        "id": "0904e5b8"
      },
      "outputs": [],
      "source": [
        "llm = ChatGoogleGenerativeAI(model =\"gemini-1.5-flash\", google_api_key = gemini_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "355edfc5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "355edfc5",
        "outputId": "ea5fa3d4-3630-46e0-8ed9-512806b788a7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'ChatGoogleGenerativeAI' object has no attribute 'GenerativeModel'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3854745485.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerativeModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gemini-pro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_mongodb_query_from_llm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema_description\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     prompt_template = f\"\"\"\n\u001b[1;32m      5\u001b[0m     \u001b[0mYou\u001b[0m \u001b[0mare\u001b[0m \u001b[0man\u001b[0m \u001b[0mAI\u001b[0m \u001b[0massistant\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mconverts\u001b[0m \u001b[0mnatural\u001b[0m \u001b[0mlanguage\u001b[0m \u001b[0mrequests\u001b[0m \u001b[0minto\u001b[0m \u001b[0mMongoDB\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    989\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m                         \u001b[0;31m# this is the current error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 991\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{type(self).__name__!r} object has no attribute {item!r}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ChatGoogleGenerativeAI' object has no attribute 'GenerativeModel'"
          ]
        }
      ],
      "source": [
        "model = llm.GenerativeModel('gemini-pro')\n",
        "\n",
        "def get_mongodb_query_from_llm(user_prompt, schema_description):\n",
        "    prompt_template = f\"\"\"\n",
        "    You are an AI assistant that converts natural language requests into MongoDB queries.\n",
        "    Given the following MongoDB collection schema:\n",
        "    {schema_description}\n",
        "\n",
        "    Convert the following user request into a MongoDB find query (JSON format):\n",
        "    User request: \"{user_prompt}\"\n",
        "    MongoDB Query:\n",
        "    \"\"\"\n",
        "    response = model.generate_content(prompt_template)\n",
        "    return response.text.strip()\n",
        "\n",
        "# Example usage\n",
        "schema_desc = \"\"\"Summary of housing data\"\"\"\n",
        "user_request = \"What is the median house price?\"\n",
        "generated_query_json = get_mongodb_query_from_llm(user_request, schema_desc)\n",
        "print(f\"Generated MongoDB Query: {generated_query_json}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}