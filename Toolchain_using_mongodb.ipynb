{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d1ea4cab",
      "metadata": {
        "id": "d1ea4cab"
      },
      "source": [
        "fyzCgTU9Iq9Fq1kj"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q google-generativeai langchain langchain-community langchain-google-genai\n",
        "!pip install pymongo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewL4gfk5ZRpP",
        "outputId": "be700223-c2e4-4ff7-a629-ee9a866a8200"
      },
      "id": "ewL4gfk5ZRpP",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.12/dist-packages (4.14.1)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from pymongo) (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ecda52a6",
      "metadata": {
        "id": "ecda52a6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from pymongo import MongoClient\n",
        "from pymongo.operations import SearchIndexModel\n",
        "from transformers import pipeline\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "mongodb_connection_string = userdata.get(\"GoogleAPIKey\")\n",
        "gemini_api_key = userdata.get(\"GoogleAPIKey\")\n"
      ],
      "metadata": {
        "id": "LrBj8iSMZ_RW"
      },
      "id": "LrBj8iSMZ_RW",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4508b636",
      "metadata": {
        "id": "4508b636"
      },
      "source": [
        "# Using HuggingFace Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "73eb8c82",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73eb8c82",
        "outputId": "95b3e19e-cc60-4dc9-eddf-104c28fa2ea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "WARNING:transformers_modules.nomic-ai.nomic-bert-2048.7710840340a098cfb869c4f65e87cf2b1b70caca.modeling_hf_nomic_bert:<All keys matched successfully>\n"
          ]
        }
      ],
      "source": [
        "model = SentenceTransformer(\"nomic-ai/nomic-embed-text-v1.5\" , trust_remote_code = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8283d9fe",
      "metadata": {
        "id": "8283d9fe"
      },
      "source": [
        "## Setting up the database\n",
        "To query a database, you first need to set one up.\n",
        "\n",
        "1. **Load the California Housing Dataset:** Load the dataset from sklearn.datasets and extract it into a DataFrame.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "california_housing_bunch = fetch_california_housing(as_frame=True)\n",
        "california_housing_df = california_housing_bunch.frame\n",
        "records = california_housing_df.to_dict(orient=\"records\")"
      ],
      "metadata": {
        "id": "jZiNgMrCa-mv"
      },
      "id": "jZiNgMrCa-mv",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a008505a",
      "metadata": {
        "id": "a008505a"
      },
      "source": [
        "2. **Connect to the mongo database and insert records:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = MongoClient(\"mongodb+srv://sunayp2020_db_user:YKFqODZHEZmeF3FI@housing.pyjgdse.mongodb.net/?retryWrites=true&w=majority&appName=Housing\")\n",
        "db = client[\"sample_db\"]\n",
        "collection = db[\"housing_data\"]\n",
        "collection.insert_many(records)\n",
        "print(\"DataFrame successfully inserted into MongoDB.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEvHWK8Uczy3",
        "outputId": "7e3f5a4a-7a28-4cbf-bbf8-0b7c9941c6bc"
      },
      "id": "mEvHWK8Uczy3",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame successfully inserted into MongoDB.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf2bbff3",
      "metadata": {
        "id": "bf2bbff3"
      },
      "source": [
        "# Creating RAG Pipeline with Langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0904e5b8",
      "metadata": {
        "id": "0904e5b8"
      },
      "outputs": [],
      "source": [
        "llm = ChatGoogleGenerativeAI(model =\"gemini-1.5-flash\", google_api_key = gemini_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "355edfc5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "355edfc5",
        "outputId": "a38251e6-beb4-48f1-a0c5-45f833011ed4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated MongoDB Query: {}\n",
            "\n",
            "Query Results:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'error': \"aizasycya4vfruhqek2ijgqxq4g8ticrigr0ny4:27017: [Errno -2] Name or service not known (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 68bea2be99c58a101b1667bb, topology_type: Unknown, servers: [<ServerDescription ('aizasycya4vfruhqek2ijgqxq4g8ticrigr0ny4', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('aizasycya4vfruhqek2ijgqxq4g8ticrigr0ny4:27017: [Errno -2] Name or service not known (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>\"}"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "genai.configure(api_key=gemini_api_key)\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "def get_mongodb_query_from_llm(user_prompt, schema_description):\n",
        "    prompt_template = f\"\"\"\n",
        "    You are an AI assistant that converts natural language requests into MongoDB queries.\n",
        "    Given the following MongoDB collection schema:\n",
        "    {schema_description}\n",
        "\n",
        "    Convert the following user request into a MongoDB find query (JSON format).\n",
        "    Only return the JSON query, no extra text or formatting.\n",
        "    User request: \"{user_prompt}\"\n",
        "    MongoDB Query:\n",
        "    \"\"\"\n",
        "    response = model.generate_content(prompt_template)\n",
        "    # Extract the JSON part from the response\n",
        "    query_text = response.text.strip()\n",
        "    # Remove markdown code block if present\n",
        "    if query_text.startswith(\"```json\"):\n",
        "        query_text = query_text[7:]\n",
        "    if query_text.endswith(\"```\"):\n",
        "        query_text = query_text[:-3]\n",
        "    return query_text.strip()\n",
        "\n",
        "import json\n",
        "from pymongo import MongoClient\n",
        "\n",
        "def execute_mongodb_query(query_json_string, db_name, collection_name, connection_string):\n",
        "    \"\"\"Executes a MongoDB find query and returns the results.\"\"\"\n",
        "    try:\n",
        "        client = MongoClient(connection_string)\n",
        "        db = client[db_name]\n",
        "        collection = db[collection_name]\n",
        "\n",
        "        query = json.loads(query_json_string)\n",
        "\n",
        "        # Check if the query is an aggregation pipeline\n",
        "        if isinstance(query, list) and all(isinstance(stage, dict) for stage in query):\n",
        "            results = list(collection.aggregate(query))\n",
        "        # Check if the query is a find query\n",
        "        elif isinstance(query, dict):\n",
        "             results = list(collection.find(query))\n",
        "        else:\n",
        "            return {\"error\": \"Invalid query format. Please provide a find query (dict) or an aggregation pipeline (list of dicts).\"}\n",
        "\n",
        "\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "    finally:\n",
        "        if 'client' in locals() and client:\n",
        "            client.close()\n",
        "\n",
        "\n",
        "# Example usage\n",
        "schema_desc = \"\"\"Summary of housing data\n",
        "Data columns (total 9 columns):\n",
        " #   Column       Non-Null Count  Dtype\n",
        "---  ------       --------------  -----\n",
        " 0   MedInc       20640 non-null  float64\n",
        " 1   HouseAge     20640 non-null  float64\n",
        " 2   AveRooms     20640 non-null  float64\n",
        " 3   AveBedrms    20640 non-null  float64\n",
        " 4   Population   20640 non-null  float64\n",
        " 5   AveOccup     20640 non-null  float64\n",
        " 6   Latitude     20640 non-null  float64\n",
        " 7   Longitude    20640 non-null  float64\n",
        " 8   MedHouseVal  20640 non-null  float64\"\"\"\n",
        "\n",
        "user_request = \"Find total number of records\"\n",
        "generated_query_json = get_mongodb_query_from_llm(user_request, schema_desc)\n",
        "print(f\"Generated MongoDB Query: {generated_query_json}\")\n",
        "\n",
        "# Replace with your actual MongoDB connection string\n",
        "# Make sure to replace \"mongodb_connection_string\" with the variable holding your connection string\n",
        "db_name = \"sample_db\"\n",
        "collection_name = \"housing_data\"\n",
        "\n",
        "query_results = execute_mongodb_query(generated_query_json, db_name, collection_name, mongodb_connection_string)\n",
        "print(\"\\nQuery Results:\")\n",
        "display(query_results) # Use display for better formatting of results"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1aTFRlzao37I"
      },
      "id": "1aTFRlzao37I",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
